{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120f1f64-b90a-4348-9399-9ccb3a1bce4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import psycopg, os\n",
    "\n",
    "print('Connecting to the PostgreSQL database...')\n",
    "conn = psycopg.connect(\n",
    "    host=\"localhost\",\n",
    "    port='5432',\n",
    "    dbname=\"Final\",\n",
    "    user=\"postgres\",\n",
    "    password=\"123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bf2540-d349-4157-8b13-bf490c2e2941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#1.stores table\n",
    "def insert_data(conn, data):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        for row in data:\n",
    "            cur.execute(\"INSERT INTO stores (store_name, location, size) VALUES (%s, %s, %s);\", row)\n",
    "        conn.commit()\n",
    "        print(\"Data inserted successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to insert data: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cur.close()\n",
    "stores_data = [\n",
    "    (\"ABC Foodmart - DUMBO\", \"123 Jay Street, Brooklyn, NY 11201\", 66),\n",
    "    (\"ABC Foodmart - Tribeca\", \"133 Chambers Street, New York, NY 10013\", 40),\n",
    "    (\"ABC Foodmart - Bay Ridge\", \"8518 3rd Ave, Brooklyn, NY 11209\", 95),\n",
    "    (\"ABC Foodmart - Whitestone\", \"153-65 Cross Island Pkwy, Whitestone, NY 11357\", 59),\n",
    "    (\"ABC Foodmart - Staten Island\", \"2655 Richmond Ave, Staten Island, NY 10314\", 82)\n",
    "]\n",
    "\n",
    "insert_data(conn, stores_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a15043-8bf6-4c87-be72-0c4a1a005a73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#2.employees table\n",
    "import pandas as pd\n",
    "\n",
    "employees_file_path = \"/Users/claudia/Desktop/employees_shifts.csv\"\n",
    "employees_data = pd.read_csv(employees_file_path)\n",
    "\n",
    "employees_data.drop_duplicates(subset=['Employee Name'], keep='first', inplace=True)\n",
    "\n",
    "new_employees_file_path = \"/Users/claudia/Desktop/employees.csv\"\n",
    "employees_data.to_csv(new_employees_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef55de96-3422-4017-8237-e78078b088d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "fake = Faker()\n",
    "\n",
    "df['phone'] = [fake.numerify('##########') for _ in range(len(df))]\n",
    "df['address'] = [fake.address() for _ in range(len(df))]\n",
    "df['entry_time'] = [fake.date_between(start_date='-5y', end_date='today') for _ in range(len(df))]\n",
    "df['shifts'] = [fake.random_element(elements=('Morning', 'Afternoon', 'Night', 'Flexible', 'Remote')) for _ in range(len(df))]\n",
    "df['time_off'] = [fake.date_time_this_decade(before_now=True, after_now=False) for _ in range(len(df))]\n",
    "df['evaluation'] = [fake.paragraph() for _ in range(len(df))]\n",
    "\n",
    "def insert_data(df, conn):\n",
    "    cur = conn.cursor()\n",
    "    for _, row in df.iterrows():\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO employees (employee_id, employee_name, store_id, title, email, phone, address, entry_time, shifts, time_off, evaluation)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\", \n",
    "            (row['employee_id'], row['employee_name'], row['store_id'], row['title'], row['email'], row['phone'], row['address'], row['entry_time'], row['shifts'], row['time_off'], row['evaluation'])\n",
    "        )\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "\n",
    "insert_data(df, conn)\n",
    "if conn:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff72f5-40c2-4108-8331-7a0df4390f2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#3. products table\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('/Users/claudia/Desktop/products_vendor_orders.csv')\n",
    "\n",
    "distinct_products = data.groupby('Product Name')['Price per Unit'].mean().reset_index()\n",
    "distinct_products.columns = ['product_name', 'cost_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eb1c6b-587a-497a-98a7-15518a4d1fb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "fake = Faker()\n",
    "\n",
    "markup_percentage = 20  \n",
    "distinct_products['selling_price'] = distinct_products['cost_price'] * (1 + markup_percentage / 100.0)\n",
    "distinct_products['selling_price'] = distinct_products['selling_price'].apply(lambda x: round(x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c1900e-2d74-4306-b1e6-510116414235",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(dbname=\"Final\", user=\"postgres\", password=\"123\", host=\"localhost\", port=\"5432\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO products (product_name, cost_price, selling_price)\n",
    "VALUES (%s, %s, %s);\n",
    "\"\"\"\n",
    "\n",
    "for index, row in distinct_products.iterrows():\n",
    "    cur.execute(insert_query, (row.product_name, row.cost_price, row.selling_price))\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf65f6a-a797-458e-a878-95c391ba4477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "def insert_data(conn, data):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        for row in data.itertuples(index=False):\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO products (product_name, cost_price, selling_price)\n",
    "                VALUES (%s, %s, %s)\n",
    "            \"\"\", row)\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        raise e\n",
    "\n",
    "try:\n",
    "\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"Final\",\n",
    "        user=\"postgres\",\n",
    "        password=\"123\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "\n",
    "    products_file_path = \"/Users/claudia/Desktop/5310 project/products.csv\" \n",
    "    products_data = pd.read_csv(products_file_path)\n",
    "\n",
    "    insert_data(conn, products_data)\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82507014-8935-4b40-8336-27e5d7ca27a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#4.inventories table\n",
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "inventories_data = []\n",
    "for _ in range(1000): \n",
    "    sku = fake.unique.uuid4()[:8]  \n",
    "    product_id = random.randint(1, 33)  \n",
    "    store_id = random.randint(1, 5)  \n",
    "    price = round(random.uniform(10.00, 1000.00), 2)  \n",
    "    quantity = random.randint(1, 100)  \n",
    "    inventories_data.append((sku, product_id, store_id, price, quantity))\n",
    "\n",
    "inventories_df = pd.DataFrame(inventories_data, columns=['sku', 'product_id', 'store_id', 'price', 'quantity'])\n",
    "\n",
    "print(inventories_df.head())\n",
    "inventories_df.to_csv('/Users/claudia/Desktop/inventories.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9321f83e-ad2b-4e97-a2fe-92903bcdda47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "def insert_data(conn, data):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        for row in data.itertuples(index=False):\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO inventories (sku, product_id, store_id, price, quantity)\n",
    "                VALUES (%s, %s, %s, %s, %s)\n",
    "            \"\"\", row)\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        raise e\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"Final\",\n",
    "        user=\"postgres\",\n",
    "        password=\"123\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "\n",
    "    inventories_file_path = \"/Users/claudia/Desktop/inventories.csv\"  \n",
    "    inventories_data = pd.read_csv(inventories_file_path)\n",
    "\n",
    "    insert_data(conn, inventories_data)\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c2a7b4-0769-4258-8ee8-da2d86d4fa65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#5.suppliers table\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "suppliers_data = []\n",
    "for i in range(1, 21):\n",
    "    supplier_id = i\n",
    "    supplier_name = fake.company()  \n",
    "    suppliers_data.append([supplier_id, supplier_name])\n",
    "\n",
    "suppliers_df = pd.DataFrame(suppliers_data, columns=['supplier_id', 'supplier_name'])\n",
    "\n",
    "print(suppliers_df.head())\n",
    "\n",
    "suppliers_df.to_csv('/Users/claudia/Desktop/suppliers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2507e41-14c3-4c90-87ea-0248c4a4a6ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "def insert_data(conn, data):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        for row in data.itertuples(index=False):\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO suppliers (supplier_name)\n",
    "                VALUES (%s)\n",
    "            \"\"\", (row[1],))  \n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        raise e\n",
    "\n",
    "try:\n",
    "\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"Final\",\n",
    "        user=\"postgres\",\n",
    "        password=\"123\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "\n",
    "    suppliers_file_path = \"/Users/claudia/Desktop/5310 project//suppliers.csv\"  \n",
    "    suppliers_data = pd.read_csv(suppliers_file_path)\n",
    "\n",
    "    insert_data(conn, suppliers_data)\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52565023-ae31-4930-a63e-34d15d7ee154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import psycopg2\n",
    "from psycopg2 import Error\n",
    "\n",
    "try:\n",
    "    connection = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port='5432',\n",
    "        dbname=\"final\",\n",
    "        user=\"postgres\",\n",
    "        password=\"123\"\n",
    "    )\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    try:\n",
    "        with open('/Users/juno/Downloads/stores.csv', 'r') as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "            next(csv_reader)  \n",
    "            for row in csv_reader:\n",
    "                \n",
    "                cursor.execute(\n",
    "                    \"INSERT INTO stores (store_name, location, size) VALUES (%s, %s, %s)\",\n",
    "                    (row[0], row[1], row[2])  \n",
    "                )\n",
    "            connection.commit()\n",
    "            print(\"CSV file imported successfully.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"The specified CSV file was not found.\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error while connecting to PostgreSQL: {e}\")\n",
    "\n",
    "finally:\n",
    "    if connection:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"PostgreSQL connection is closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98036f9f-2ae5-4f37-b89e-f899b1af8af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import psycopg2\n",
    "from psycopg2 import Error\n",
    "\n",
    "try:\n",
    "    connection = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port='5432',\n",
    "        dbname=\"final\",\n",
    "        user=\"postgres\",\n",
    "        password=\"123\"\n",
    "    )\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    try:\n",
    "        with open('/Users/juno/Desktop/5310/PROJECT/suppliers table.csv', 'r') as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "            next(csv_reader)  \n",
    "            for row in csv_reader:\n",
    "                cursor.execute(\n",
    "                    \"INSERT INTO suppliers (supplier_name) VALUES (%s)\",\n",
    "                    (row[1],) \n",
    "                )\n",
    "            connection.commit()\n",
    "            print(\"CSV file imported successfully.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"The specified CSV file was not found.\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error while connecting to PostgreSQL: {e}\")\n",
    "\n",
    "finally:\n",
    "    if connection:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"PostgreSQL connection is closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e031db17-c003-4f98-8287-3243d60d1205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.shipments table\n",
    "import json\n",
    "from faker import Faker\n",
    "import random\n",
    "import datetime\n",
    "import uuid\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port='5432',\n",
    "        dbname=\"final\",\n",
    "        user=\"postgres\",\n",
    "        password=\"123\"\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "start_date = datetime.date(2024, 1, 1)\n",
    "end_date = datetime.date(2025, 12, 31)\n",
    "delivery_dates = [fake.date_between(start_date=start_date, end_date=end_date) for _ in range(5)]\n",
    "actual_delivery_data = {}\n",
    "for delivery_date in delivery_dates:\n",
    "    actual_delivery_data[delivery_date.strftime('%Y-%m-%d')] = fake.date_time_between_dates(\n",
    "        datetime_start=datetime.datetime.now(),\n",
    "        datetime_end=datetime.datetime.now() + datetime.timedelta(days=30)\n",
    "    )\n",
    "\n",
    "store_names = [\"ABC Foodmart - DUMBO\",\"ABC Foodmart - Tribeca\",\"ABC Foodmart - Bay Ridge\",\"ABC Foodmart - Whitestone\",\"ABC Foodmart - Staten Island\"]\n",
    "\n",
    "fake_shipments = []\n",
    "for _ in range(5000):  \n",
    "    store_name = random.choice(store_names)  \n",
    "    supplier_id = random.randint(1, 20)  \n",
    "    delivery_date = random.choice(delivery_dates).strftime('%Y-%m-%d')  \n",
    "    product_list = json.dumps({'product1': random.randint(1, 100), 'product2': random.randint(1, 100)})  \n",
    "    discrepancies = json.dumps({'discrepancy1': random.randint(1, 10), 'discrepancy2': random.randint(1, 10)})  \n",
    "    \n",
    "    \n",
    "    shipment_id = str(uuid.uuid4())[:8]  \n",
    "    \n",
    "    fake_shipments.append((\n",
    "        shipment_id,  \n",
    "        store_name,  \n",
    "        supplier_id,  \n",
    "        product_list,  \n",
    "        datetime.datetime.now(),  \n",
    "        actual_delivery_data.get(delivery_date),  \n",
    "        discrepancies  \n",
    "    ))\n",
    "\n",
    "try:\n",
    "    cursor.executemany(\"\"\"\n",
    "        INSERT INTO shipments (shipment_id, store_id, supplier_id, product_list, expected_delivery, actual_delivery, discrepancies)\n",
    "        VALUES (%s, (SELECT store_id FROM stores WHERE store_name = %s), %s, %s, %s, %s, %s)\n",
    "    \"\"\", fake_shipments)\n",
    "    connection.commit()\n",
    "    print(\"Data inserted successfully.\")\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error inserting data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de52c324-a37a-49c9-bc82-965afe26052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e0b29b-6bef-4c74-bf5e-b8fdc69103ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.supplier_evaluations table\n",
    "connection = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port='5432',\n",
    "        dbname=\"final\",\n",
    "        user=\"postgres\",\n",
    "        password=\"123\"\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "fake_evaluations = []\n",
    "for _ in range(40):\n",
    "    supplier_id = random.randint(1, 20)  \n",
    "    date = fake.date_between(start_date='-1y', end_date='today')  \n",
    "    responsiveness_rating = random.randint(1, 5)  \n",
    "    productquality_rating = random.randint(1, 5)  \n",
    "    deliveryaccuracy_rating = random.randint(1, 5)  \n",
    "    comments = fake.paragraph()  \n",
    "    \n",
    "    fake_evaluations.append((\n",
    "        supplier_id,\n",
    "        date,\n",
    "        responsiveness_rating,\n",
    "        productquality_rating,\n",
    "        deliveryaccuracy_rating,\n",
    "        comments\n",
    "    ))\n",
    "\n",
    "try:\n",
    "    cursor.executemany(\"\"\"\n",
    "        INSERT INTO supplier_evaluations (supplier_id, date, responsiveness_rating, productquality_rating, deliveryaccuracy_rating, comments)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", fake_evaluations)\n",
    "    connection.commit()\n",
    "    print(\"Fake evaluations inserted successfully.\")\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error inserting fake evaluations: {e}\")\n",
    "\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83294c95-5283-4de1-b219-b96f3b01519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.customers table\n",
    "connection = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port='5432',\n",
    "        dbname=\"final\",\n",
    "        user=\"postgres\",\n",
    "        password=\"123\"\n",
    ")\n",
    "\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "customer_totals = {}\n",
    "with open('/Users/juno/Desktop/5310/PROJECT/customers_sales.csv', 'r') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    for row in csv_reader:\n",
    "        customer_name = row['Customer Name']\n",
    "        email = row['Customer Email']\n",
    "        price_per_unit = float(row['Price per Unit'])\n",
    "        quantity = int(row['Quantity'])\n",
    "        total_purchase = price_per_unit * quantity\n",
    "\n",
    "        if customer_name in customer_totals:\n",
    "            customer_totals[customer_name] += total_purchase\n",
    "        else:\n",
    "            customer_totals[customer_name] = total_purchase\n",
    "\n",
    "try:\n",
    "    for customer_name, total_purchase in customer_totals.items():\n",
    "        email = fake.email()\n",
    "        phone = fake.phone_number()\n",
    "        address = fake.address()\n",
    "        loyalty_points = random.randint(0, 100)\n",
    "        last_purchase_date = fake.date_between(start_date='-1y', end_date='today')\n",
    "\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO customers (customer_name, email, phone, address, loyalty_points, total_purchases, last_purchase_date)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\", (customer_name, email, phone, address, loyalty_points, total_purchase, last_purchase_date))\n",
    "\n",
    "    connection.commit()\n",
    "    print(\"Data inserted successfully.\")\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error inserting data: {e}\")\n",
    "\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbc9e60-f26d-4b49-92b1-19bbd8936523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9.orders table\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "import psycopg2\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port='5432',\n",
    "    dbname=\"final\",\n",
    "    user=\"postgres\",\n",
    "    password=\"123\"\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "orders_data = {}\n",
    "with open('/Users/juno/Desktop/5310/PROJECT/customers_sales.csv', 'r') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    for row in csv_reader:\n",
    "        cursor.execute(\"SELECT customer_id FROM customers WHERE customer_name = %s\", (row['Customer Name'],))\n",
    "        customer_id = cursor.fetchone()[0] if cursor.rowcount > 0 else None\n",
    "        cursor.execute(\"SELECT store_id FROM stores WHERE store_name = %s\", (row['Store Name'],))\n",
    "        store_id = cursor.fetchone()[0] if cursor.rowcount > 0 else None\n",
    "        if customer_id and store_id:\n",
    "            order_time = datetime.strptime(row['Date of Purchase'], '%Y-%m-%d %H:%M')  \n",
    "            total_amount = float(row['Price per Unit']) * int(row['Quantity'])  \n",
    "            items_purchased = {row['Product Name']: int(row['Quantity'])}  \n",
    "\n",
    "            key = (customer_id, order_time)\n",
    "            if key in orders_data:\n",
    "                orders_data[key]['total_amount'] += total_amount\n",
    "                for item, quantity in items_purchased.items():\n",
    "                    orders_data[key]['items_purchased'].setdefault(item, 0)\n",
    "                    orders_data[key]['items_purchased'][item] += quantity\n",
    "            else:\n",
    "                orders_data[key] = {\n",
    "                    'customer_id': customer_id,\n",
    "                    'order_time': order_time,\n",
    "                    'total_amount': total_amount,\n",
    "                    'items_purchased': items_purchased\n",
    "                }\n",
    "\n",
    "for order_info in orders_data.values():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO orders (customer_id, store_id, order_time, total_amount, items_purchased)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "    \"\"\", (order_info['customer_id'], store_id, order_info['order_time'], order_info['total_amount'],\n",
    "          json.dumps(order_info['items_purchased'])))\n",
    "\n",
    "connection.commit()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43b145-bbf9-4714-b565-a188726489f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.sales table\n",
    "try:\n",
    "    connection = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port='5432',\n",
    "        dbname=\"final\",\n",
    "        user=\"postgres\",\n",
    "        password=\"123\"\n",
    "    )\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    try:\n",
    "        with open('/Users/juno/Downloads/products table.csv', 'r') as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "            next(csv_reader)  \n",
    "            for row in csv_reader:\n",
    "                try:\n",
    "                    product_name = row[1] \n",
    "                    cost_price = float(row[2])  \n",
    "                    selling_price = float(row[3])  \n",
    "                    cursor.execute(\n",
    "                        \"INSERT INTO products (product_name, cost_price, selling_price) VALUES (%s, %s, %s)\",\n",
    "                        (product_name, cost_price, selling_price)\n",
    "                    )\n",
    "                except (ValueError, IndexError) as e:\n",
    "                    print(f\"Error processing row: {row}. {e}\")\n",
    "            connection.commit()\n",
    "            print(\"CSV file imported successfully.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"The specified CSV file was not found.\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error while connecting to PostgreSQL: {e}\")\n",
    "\n",
    "finally:\n",
    "    if connection:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"PostgreSQL connection is closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ef4a65-4c0f-4cc8-a78a-ff870b87ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    connection = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port='5432',\n",
    "        dbname=\"final\",\n",
    "        user=\"postgres\",\n",
    "        password=\"123\"\n",
    "    )\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    try:\n",
    "        with open('/Users/juno/Downloads/products table.csv', 'r') as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "            next(csv_reader)  \n",
    "            for row in csv_reader:\n",
    "                try:\n",
    "                    product_name = row[1] \n",
    "                    cost_price = float(row[2])  \n",
    "                    selling_price = float(row[3])  \n",
    "                    cursor.execute(\n",
    "                        \"INSERT INTO products (product_name, cost_price, selling_price) VALUES (%s, %s, %s)\",\n",
    "                        (product_name, cost_price, selling_price)\n",
    "                    )\n",
    "                except (ValueError, IndexError) as e:\n",
    "                    print(f\"Error processing row: {row}. {e}\")\n",
    "            connection.commit()\n",
    "            print(\"CSV file imported successfully.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"The specified CSV file was not found.\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error while connecting to PostgreSQL: {e}\")\n",
    "\n",
    "finally:\n",
    "    if connection:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"PostgreSQL connection is closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2671a37-1658-4c74-9917-af53f3d734df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_store_id(cursor, store_name):\n",
    "    cursor.execute(\"SELECT store_id FROM stores WHERE store_name = %s\", (store_name,))\n",
    "    result = cursor.fetchone()\n",
    "    if result:\n",
    "        return result[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_product_id(cursor, product_name):\n",
    "    cursor.execute(\"SELECT product_id FROM products WHERE product_name = %s\", (product_name,))\n",
    "    result = cursor.fetchone()\n",
    "    if result:\n",
    "        return result[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port='5432',\n",
    "    dbname=\"final\",\n",
    "    user=\"postgres\",\n",
    "    password=\"123\"\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "fake = Faker()\n",
    "\n",
    "with open('/Users/juno/Desktop/5310/PROJECT/customers_sales.csv', 'r') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    for row in csv_reader:\n",
    "        store_id = get_store_id(cursor, row['Store Name'])\n",
    "        product_id = get_product_id(cursor, row['Product Name'])\n",
    "        payment_method = fake.random_element(elements=('Cash', 'Credit Card', 'PayPal', 'Bitcoin'))\n",
    "        sale_time = datetime.strptime(row['Date of Purchase'], '%Y-%m-%d %H:%M')\n",
    "\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO sales (store_id, product_id, quantity, selling_price, sale_time, payment_method)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s)\n",
    "        \"\"\", (store_id, product_id, int(row['Quantity']), float(row['Price per Unit']), sale_time, payment_method))\n",
    "\n",
    "connection.commit()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190e4d98-dc36-4d17-bc47-9e56341337e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. expenses table\n",
    "import csv\n",
    "import random\n",
    "from faker import Faker\n",
    "import psycopg2\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "store_id_file_path = '/Users/ruby/Desktop/5310 final/stores table.csv'\n",
    "\n",
    "\n",
    "valid_store_ids = []\n",
    "with open(store_id_file_path, 'r') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    for row in csv_reader:\n",
    "        valid_store_ids.append(row['store_id'])\n",
    "\n",
    "expense_types = ['Rent', 'Utilities', 'Supplies', 'Maintenance', 'Marketing']\n",
    "\n",
    "expenses_file_path = '/Users/ruby/Desktop/5310 final/expenses.csv'\n",
    "with open(expenses_file_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['expense_id', 'store_id', 'expense_type', 'amount', 'expense_date'])\n",
    "    expense_id = 1\n",
    "    for _ in range(100): \n",
    "        store_id = random.choice(valid_store_ids)\n",
    "        expense_type = random.choice(expense_types)\n",
    "        amount = round(random.uniform(100, 10000), 2)\n",
    "        expense_date = fake.date_between(start_date='-1y', end_date='today')\n",
    "        writer.writerow([expense_id, store_id, expense_type, amount, expense_date])\n",
    "        expense_id += 1\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port='5432',\n",
    "    dbname=\"5310 Final\",  \n",
    "    user=\"postgres\",\n",
    "    password=\"123\"      \n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    with open(expenses_file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader) \n",
    "        for row in reader:\n",
    "            expense_id, store_id, expense_type, amount, expense_date = row\n",
    "            cur.execute(\"INSERT INTO expenses (expense_id, store_id, expense_type, amount, expense_date) VALUES (%s, %s, %s, %s, %s)\", (expense_id, store_id, expense_type, amount, expense_date))\n",
    "    conn.commit()\n",
    "    print(\"Expense data successfully inserted!\")\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error inserting expense data: {e}\")\n",
    "    conn.rollback()\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5f7cf-21f6-455a-b4ec-76741f772f03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#12.demand_forecast table\n",
    "import csv\n",
    "import random\n",
    "from faker import Faker\n",
    "import psycopg2\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "forecast_file_path = '/Users/claudia/Desktop/demand_forecast.csv'\n",
    "\n",
    "conn_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": '5432',\n",
    "    \"dbname\": \"group4\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"123\"\n",
    "}\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(**conn_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "cur.execute(\"SELECT DISTINCT sku FROM inventories\")\n",
    "valid_skus = [row[0] for row in cur.fetchall()]\n",
    "\n",
    "\n",
    "with open(forecast_file_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['forecast_id', 'product_id', 'sku', 'forecast_date', 'forecast_quantity', 'actual_quantity', 'previous_sales', 'season'])\n",
    "    forecast_id = 1\n",
    "    for _ in range(100):\n",
    "        product_id = random.randint(1, 33)  \n",
    "        sku = random.choice(valid_skus)\n",
    "        forecast_date = fake.date_between(start_date='-1y', end_date='today')\n",
    "        forecast_quantity = random.randint(50, 500)\n",
    "        actual_quantity = random.randint(50, 500)\n",
    "        previous_sales = round(random.uniform(1000, 50000), 2)\n",
    "        season = random.choice(['Spring', 'Summer', 'Fall', 'Winter'])\n",
    "        writer.writerow([forecast_id, product_id, sku, forecast_date, forecast_quantity, actual_quantity, previous_sales, season])\n",
    "        forecast_id += 1\n",
    "\n",
    "try:\n",
    "    with open(forecast_file_path, 'r') as file:\n",
    "        next(csv.reader(file)) \n",
    "        cur.copy_from(file, 'demand_forecast', sep=',')\n",
    "    conn.commit()\n",
    "    print(\"Demand forecast data successfully inserted!\")\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error inserting demand forecast data: {e}\")\n",
    "    conn.rollback()\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d44c603-fd92-41a0-9df8-6055ece94461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#13. promotions table\n",
    "import csv\n",
    "import random\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta\n",
    "import psycopg2\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "store_id_file_path = '/Users/ruby/Desktop/5310 final/stores table.csv'\n",
    "\n",
    "valid_store_ids = []\n",
    "with open(store_id_file_path, 'r') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    for row in csv_reader:\n",
    "        valid_store_ids.append(row['store_id'])\n",
    "\n",
    "\n",
    "promotions_file_path = '/Users/claudia/Desktop/5310 final/promotions.csv'\n",
    "with open(promotions_file_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['promotion_id', 'promotion_name', 'store_id', 'start_time', 'end_time', 'description', 'discount_percentage'])\n",
    "    for i in range(100): \n",
    "        promotion_id = i + 1\n",
    "        promotion_name = fake.catch_phrase()\n",
    "        store_id = random.choice(valid_store_ids)\n",
    "        start_time = fake.date_time_between(start_date='-1y', end_date='now')\n",
    "        end_time = start_time + timedelta(days=random.randint(1, 14))  \n",
    "        description = fake.text(max_nb_chars=200)\n",
    "        discount_percentage = round(random.uniform(5, 50), 2)  \n",
    "        writer.writerow([promotion_id, promotion_name, store_id, start_time, end_time, description, discount_percentage])\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port='5432',\n",
    "    dbname=\"group4\",  \n",
    "    user=\"postgres\",\n",
    "    password=\"123\"         \n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    with open(promotions_file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  \n",
    "        for row in reader:\n",
    "            promotion_id, promotion_name, store_id, start_time, end_time, description, discount_percentage = row\n",
    "            cur.execute(\"INSERT INTO promotions (promotion_id, promotion_name, store_id, start_time, end_time, description, discount_percentage) VALUES (%s, %s, %s, %s, %s, %s, %s)\", (promotion_id, promotion_name, store_id, start_time, end_time, description, discount_percentage))\n",
    "    conn.commit()\n",
    "    print(\"Promotion data successfully inserted!\")\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error inserting promotion data: {e}\")\n",
    "    conn.rollback()\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e1d045-878c-4ee0-b861-b99374b32396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14.promotion_effects table\n",
    "import csv\n",
    "import random\n",
    "from faker import Faker\n",
    "import psycopg2\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "promotion_id_file_path = '/Users/ruby/Desktop/5310 final/promotions.csv'\n",
    "sku_file_path = '/Users/ruby/Desktop/5310 final/inventories table.csv'\n",
    "effects_file_path = '/Users/ruby/Desktop/5310 final/promotion_effects.csv'\n",
    "\n",
    "valid_promotion_ids = []\n",
    "with open(promotion_id_file_path, 'r') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    for row in csv_reader:\n",
    "        valid_promotion_ids.append(row['promotion_id'])\n",
    "\n",
    "valid_skus = []\n",
    "with open(sku_file_path, 'r') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    for row in csv_reader:\n",
    "        valid_skus.append(row['sku'])\n",
    "\n",
    "with open(effects_file_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['effect_id', 'promotion_id', 'sku', 'sales_quantity', 'revenue', 'comments'])\n",
    "    for i in range(100):  \n",
    "        effect_id = i + 1\n",
    "        promotion_id = random.choice(valid_promotion_ids)\n",
    "        sku = random.choice(valid_skus)\n",
    "        sales_quantity = random.randint(10, 1000)  \n",
    "        revenue = round(sales_quantity * random.uniform(10, 100), 2)  \n",
    "        comments = fake.text(max_nb_chars=200)\n",
    "        writer.writerow([effect_id, promotion_id, sku, sales_quantity, revenue, comments])\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port='5432',\n",
    "    dbname=\"5310 Final\",  \n",
    "    user=\"postgres\",\n",
    "    password=\"123\"       \n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    with open(effects_file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader) \n",
    "        for row in reader:\n",
    "            effect_id, promotion_id, sku, sales_quantity, revenue, comments = row\n",
    "            cur.execute(\"INSERT INTO promotion_effects (effect_id, promotion_id, sku, sales_quantity, revenue, comments) VALUES (%s, %s, %s, %s, %s, %s)\", (effect_id, promotion_id, sku, sales_quantity, revenue, comments))\n",
    "    conn.commit()\n",
    "    print(\"Promotion effects data successfully inserted!\")\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error inserting promotion effects data: {e}\")\n",
    "    conn.rollback()\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ebd81e-88c9-4a2e-9372-0200fabc97bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#15.customer_satisfaction table\n",
    "import csv\n",
    "import random\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta\n",
    "import psycopg2\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "conn_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": '5432',\n",
    "    \"dbname\": \"group4\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"123\"\n",
    "}\n",
    "\n",
    "conn = psycopg2.connect(**conn_params)\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "cur.execute(\"SELECT store_id FROM stores\")\n",
    "valid_store_ids = [row[0] for row in cur.fetchall()]\n",
    "\n",
    "\n",
    "cur.execute(\"SELECT customer_id FROM customers\")\n",
    "valid_customer_ids = [row[0] for row in cur.fetchall()]\n",
    "\n",
    "satisfaction_file_path = '/Users/claudia/Desktop/customer_satisfaction.csv'\n",
    "\n",
    "with open(satisfaction_file_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['survey_id', 'customer_id', 'store_id', 'survey_date', 'rating', 'comments', 'follow_up_required', 'follow_up_date'])\n",
    "    for i in range(100):\n",
    "        survey_id = fake.unique.bothify(text='?????#####')  \n",
    "        customer_id = random.choice(valid_customer_ids)  \n",
    "        store_id = random.choice(valid_store_ids) \n",
    "        survey_date = fake.date_between(start_date='-2y', end_date='today').strftime('%Y-%m-%d')\n",
    "        rating = random.randint(1, 5)\n",
    "        comments = fake.text(max_nb_chars=200)\n",
    "        follow_up_required = fake.boolean(chance_of_getting_true=25)\n",
    "        follow_up_date = (datetime.strptime(survey_date, '%Y-%m-%d') + timedelta(days=30)).strftime('%Y-%m-%d') if follow_up_required else None\n",
    "        writer.writerow([survey_id, customer_id, store_id, survey_date, rating, comments, follow_up_required, follow_up_date])\n",
    "\n",
    "try:\n",
    "    with open(satisfaction_file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader) \n",
    "        for row in reader:\n",
    "            survey_id, customer_id, store_id, survey_date, rating, comments, follow_up_required, follow_up_date = row\n",
    "            cur.execute(\"INSERT INTO customer_satisfaction (survey_id, customer_id, store_id, survey_date, rating, comments, follow_up_required, follow_up_date) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\", \n",
    "                        (survey_id, customer_id, store_id, survey_date, rating, comments, bool(follow_up_required), follow_up_date if follow_up_date else None))\n",
    "    conn.commit()\n",
    "    print(\"Customer satisfaction data successfully inserted!\")\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error inserting customer satisfaction data: {e}\")\n",
    "    conn.rollback()\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae0fe7-24ca-4ef5-841f-1eafd5e6d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16.training_sessions table\n",
    "import random\n",
    "import string\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "import csv\n",
    "import psycopg2\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "with open('D:/columbia/5310/training_sessions.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['session_id', 'topic', 'trainer', 'training_date', 'training_place', 'duration', 'effectiveness_rating'])\n",
    "    for _ in range(50):\n",
    "        session_id = ''.join(random.choices(string.ascii_uppercase + string.digits, k=8))\n",
    "        topic = fake.sentence(nb_words=5)\n",
    "        trainer = fake.name()\n",
    "        training_date = fake.date_between(start_date='-1y', end_date='today')\n",
    "        training_place = fake.city()\n",
    "        duration = random.randint(1, 8)\n",
    "        effectiveness_rating = random.randint(1, 5)\n",
    "        writer.writerow([session_id, topic, trainer, training_date, training_place, duration, effectiveness_rating])\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port='5432',\n",
    "    dbname=\"finalfinal\",\n",
    "    user=\"postgres\",\n",
    "    password=\"123\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    with open('D:/columbia/5310/training_sessions.csv', 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  \n",
    "        for row in reader:\n",
    "            cur.execute(\"INSERT INTO training_sessions (session_id, topic, trainer, training_date, training_place, duration, effectiveness_rating) VALUES (%s, %s, %s, %s, %s, %s, %s)\", row)\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"training_sessions数据插入成功!\")\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"插入training_sessions数据时出错: {e}\")\n",
    "    conn.rollback()\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f54365-b2f7-4b10-8125-2057627f4421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17.employee_training table\n",
    "import csv\n",
    "import random\n",
    "from datetime import datetime\n",
    "from faker import Faker\n",
    "import psycopg2\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "with open('/Users/claudia/Desktop/5310 Group4 tables/employees.csv', 'r') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    valid_employee_ids = [row['employee_id'].strip() for row in csv_reader]\n",
    "\n",
    "with open('/Users/claudia/Desktop/5310 Group4 tables/training_sessions.csv', 'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader) \n",
    "    valid_session_ids = [row[0].strip() for row in csv_reader]\n",
    "\n",
    "with open('/Users/claudia/Desktop/employee_training.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['employee_id', 'session_id', 'participation_date', 'evaluation'])\n",
    "    for _ in range(100):\n",
    "        employee_id = random.choice(valid_employee_ids)\n",
    "        session_id = random.choice(valid_session_ids)\n",
    "        participation_date = fake.date_between(start_date='-1y', end_date='today').isoformat()\n",
    "        evaluation = fake.paragraph(nb_sentences=3)\n",
    "        writer.writerow([employee_id, session_id, participation_date, evaluation])\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port='5432',\n",
    "    dbname=\"group4\",\n",
    "    user=\"postgres\",\n",
    "    password=\"123\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    with open('/Users/claudia/Desktop/employee_training.csv', 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader) \n",
    "        cur.executemany(\"INSERT INTO employee_training (employee_id, session_id, participation_date, evaluation) VALUES (%s, %s, %s, %s)\", \n",
    "                        (row for row in reader))\n",
    "    conn.commit()\n",
    "    print(\"Data successfully inserted into employee_training!\")\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error during data insertion: {e}\")\n",
    "    conn.rollback()\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77d4058-c601-496a-8769-da4f35bf07da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#18.returns table\n",
    "import random\n",
    "from faker import Faker\n",
    "import csv\n",
    "import psycopg2\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "with open('/Users/claudia/Desktop/5310 Group4 tables/customers.csv', 'r') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    valid_customer_ids = [row['customer_id'] for row in csv_reader]\n",
    "\n",
    "with open('/Users/claudia/Desktop/5310 Group4 tables/orders.csv', 'r') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    valid_order_ids = [row['order_id'] for row in csv_reader]\n",
    "\n",
    "with open('/Users/claudia/Desktop/5310 Group4 tables/products.csv', 'r') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    valid_product_ids = [row['product_id'] for row in csv_reader]\n",
    "\n",
    "with open('/Users/claudia/Desktop/5310 Group4 tables/stores.csv', 'r') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    valid_store_ids = [row['store_id'] for row in csv_reader]\n",
    "\n",
    "with open('/Users/claudia/Desktop/5310 Group4 tables/returns.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['order_id', 'customer_id', 'product_id', 'store_id', 'return_date', 'reason', 'satisfaction_level', 'action_taken'])\n",
    "    for _ in range(200):\n",
    "        order_id = random.choice(valid_order_ids)\n",
    "        customer_id = random.choice(valid_customer_ids)\n",
    "        product_id = random.choice(valid_product_ids)\n",
    "        store_id = random.choice(valid_store_ids)\n",
    "        return_date = fake.date_between(start_date='-1y', end_date='today')\n",
    "        reason = fake.sentence(nb_words=10)\n",
    "        satisfaction_level = random.randint(1, 5)\n",
    "        action_taken = fake.sentence(nb_words=5)\n",
    "        writer.writerow([order_id, customer_id, product_id, store_id, return_date, reason, satisfaction_level, action_taken])\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port='5432',\n",
    "    dbname=\"group4\",\n",
    "    user=\"postgres\",\n",
    "    password=\"123\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    with open('/Users/claudia/Desktop/5310 Group4 tables/returns.csv', 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  \n",
    "        for row in reader:\n",
    "            order_id = row[0]\n",
    "            customer_id = row[1]\n",
    "            product_id = row[2]\n",
    "            store_id = row[3]\n",
    "            return_date = row[4]\n",
    "            reason = row[5]\n",
    "            satisfaction_level = row[6]\n",
    "            action_taken = row[7]\n",
    "            cur.execute(\"INSERT INTO returns (order_id, customer_id, product_id, store_id, return_date, reason, satisfaction_level, action_taken) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\", (order_id, customer_id, product_id, store_id, return_date, reason, satisfaction_level, action_taken))\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"returns数据插入成功!\")\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"插入returns数据时出错: {e}\")\n",
    "    conn.rollback()\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4263a9a0-ca8e-4ef7-ab29-a958b7ece047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#19.exchanges table\n",
    "import random\n",
    "from faker import Faker\n",
    "import csv\n",
    "import psycopg2\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "with open('/Users/claudia/Desktop/5310 Group4 tables/customers.csv', 'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)\n",
    "    valid_customer_ids = [row[0] for row in csv_reader]\n",
    "\n",
    "with open('/Users/claudia/Desktop/5310 Group4 tables/orders.csv', 'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)\n",
    "    valid_order_ids = [row[0] for row in csv_reader]\n",
    "\n",
    "with open('/Users/claudia/Desktop/5310 Group4 tables/products.csv', 'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)\n",
    "    valid_product_ids = [row[0] for row in csv_reader]\n",
    "\n",
    "with open('/Users/claudia/Desktop/5310 Group4 tables/stores.csv', 'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)\n",
    "    valid_store_ids = [row[0] for row in csv_reader]\n",
    "\n",
    "with open('/Users/claudia/Desktop/5310 Group4 tables/exchanges.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['order_id', 'customer_id', 'product_id', 'store_id', 'exchange_date', 'reason', 'satisfaction_level', 'action_taken'])\n",
    "    for _ in range(200):\n",
    "        order_id = random.choice(valid_order_ids)\n",
    "        customer_id = random.choice(valid_customer_ids)\n",
    "        product_id = random.choice(valid_product_ids)\n",
    "        store_id = random.choice(valid_store_ids)\n",
    "        exchange_date = fake.date_between(start_date='-1y', end_date='today').isoformat()\n",
    "        reason = fake.sentence(nb_words=10)\n",
    "        satisfaction_level = random.randint(1, 5)\n",
    "        action_taken = fake.sentence(nb_words=5)\n",
    "        writer.writerow([order_id, customer_id, product_id, store_id, exchange_date, reason, satisfaction_level, action_taken])\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port='5432',\n",
    "    dbname=\"group4\",\n",
    "    user=\"postgres\",\n",
    "    password=\"123\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    with open('/Users/claudia/Desktop/5310 Group4 tables/exchanges.csv', 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader) \n",
    "        for row in reader:\n",
    "            cur.execute(\"INSERT INTO exchanges (order_id, customer_id, product_id, store_id, exchange_date, reason, satisfaction_level, action_taken) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\", tuple(row))\n",
    "    conn.commit()\n",
    "    print(\"exchanges数据插入成功!\")\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"插入exchanges数据时出错: {e}\")\n",
    "    conn.rollback()\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5dfca629-01c4-440b-9cdc-8ed3a1bb2508",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "插入waste数据时出错: insert or update on table \"waste\" violates foreign key constraint \"waste_sku_fkey\"\n",
      "DETAIL:  Key (sku)=(f91a528d) is not present in table \"inventories\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#20.waste table\n",
    "import random\n",
    "from faker import Faker\n",
    "import csv\n",
    "import psycopg2\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "valid_product_ids = fetch_valid_ids('/Users/claudia/Desktop/5310 Group4 tables/products.csv')\n",
    "valid_skus = fetch_valid_ids('/Users/claudia/Desktop/inventories.csv')\n",
    "valid_store_ids = fetch_valid_ids('/Users/claudia/Desktop/5310 Group4 tables/stores.csv')\n",
    "\n",
    "with open('/Users/claudia/Desktop/5310 Group4 tables/waste.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['waste_id', 'product_id', 'sku', 'store_id', 'date', 'type', 'quantity', 'disposal_method', 'notes'])\n",
    "    for i in range(300):\n",
    "        writer.writerow([\n",
    "            i + 1,\n",
    "            random.choice(valid_product_ids),\n",
    "            random.choice(valid_skus),\n",
    "            random.choice(valid_store_ids),\n",
    "            fake.date_between(start_date='-1y', end_date='today').isoformat(),\n",
    "            random.choice(['expired', 'damaged']),\n",
    "            random.randint(1, 100),\n",
    "            random.choice(['recycling', 'landfill']),\n",
    "            fake.sentence(nb_words=10)\n",
    "        ])\n",
    "\n",
    "conn = psycopg2.connect(host=\"localhost\", port='5432', dbname=\"group4\", user=\"postgres\", password=\"123\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    with open('/Users/claudia/Desktop/5310 Group4 tables/waste.csv', 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  \n",
    "        for row in reader:\n",
    "            cur.execute(\"INSERT INTO waste (waste_id, product_id, sku, store_id, date, type, quantity, disposal_method, notes) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\", tuple(row))\n",
    "    conn.commit()\n",
    "    print(\"Waste data successfully inserted!\")\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error inserting waste data: {e}\")\n",
    "    conn.rollback()\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a3b47-12df-4708-a963-ba80c9b0ef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#21.zones table\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "zone_categories = ['produce', 'dairy and eggs', 'meat and seafood', 'frozen foods', 'dry foods', 'delicatessen', 'bakery', 'beverages', 'health and beauty', 'checkout']\n",
    "\n",
    "zones_data = []\n",
    "\n",
    "\n",
    "number_of_stores = 5\n",
    "zones_per_store = len(zone_categories)\n",
    "\n",
    "for store_id in range(1, number_of_stores + 1):\n",
    "    for zone_index in range(zones_per_store):\n",
    "        zone_id = (store_id - 1) * zones_per_store + zone_index + 1\n",
    "        zone_name = zone_categories[zone_index]\n",
    "        zones_data.append({\n",
    "            'zone_id': zone_id,\n",
    "            'store_id': store_id,\n",
    "            'zone_name': zone_name\n",
    "        })\n",
    "\n",
    "\n",
    "zones_df = pd.DataFrame(zones_data)\n",
    "\n",
    "print(zones_df)\n",
    "zones_df.to_csv('/Users/jintonghe/zones.csv', index=False)\n",
    "\n",
    "print(\"CSV file 'zones.csv' has been saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596d56b-177c-4290-a401-921fc209f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "def insert_data(conn, data):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        for row in data.itertuples(index=False):\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO zones (zone_name)\n",
    "                VALUES (%s)\n",
    "            \"\"\", (row[1],))  \n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        raise e\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"Final\",\n",
    "        user=\"postgres\",\n",
    "        password=\"123\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "\n",
    "    zones_file_path = \"/Users/jintonghe/zones.csv\" \n",
    "    zones_data = pd.read_csv(zones_file_path)\n",
    "\n",
    "    insert_data(conn, zones_data)\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd22dec9-1ae3-47d6-86f8-be49210d2100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#22.foot_traffic table\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "from datetime import timedelta\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "number_of_zones = 50\n",
    "number_of_records = 1000  \n",
    "\n",
    "foot_traffic_data = []\n",
    "\n",
    "for i in range(number_of_records):\n",
    "    traffic_id = i + 1  \n",
    "    zone_id = fake.random_int(min=1, max=number_of_zones)  \n",
    "    start_time = fake.date_time()  \n",
    "    end_time = start_time + timedelta(minutes=fake.random_int(min=5, max=60))  \n",
    "    customer_count = fake.random_int(min=0, max=100)  \n",
    "\n",
    "    foot_traffic_data.append({\n",
    "        'traffic_id': traffic_id,\n",
    "        'zone_id': zone_id,\n",
    "        'start_time': start_time,\n",
    "        'end_time': end_time,\n",
    "        'customer_count': customer_count\n",
    "    })\n",
    "\n",
    "foot_traffic_df = pd.DataFrame(foot_traffic_data)\n",
    "\n",
    "print(foot_traffic_df.head())\n",
    "\n",
    "\n",
    "foot_traffic_df.to_csv('/Users/jintonghe/zones.csv', index=False)\n",
    "\n",
    "print(\"CSV file 'foot_traffic.csv' has been saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d5b41-69b7-4ae0-876b-270c6fb78aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "def insert_foot_traffic_data(conn, df):\n",
    "    cur = conn.cursor()\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO foot_traffic (traffic_id, zone_id, start_time, end_time, customer_count)\n",
    "        VALUES %s\n",
    "    \"\"\"\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    execute_values(cur, insert_query, tuples)\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"Final\",\n",
    "        user=\"postgres\",\n",
    "        password=\"123\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "\n",
    "    foot_traffic_file_path = \"/Users/jintonghe/foot_traffic.csv\"  \n",
    "    foot_traffic_df = pd.read_csv(foot_traffic_file_path)\n",
    "\n",
    "    insert_foot_traffic_data(conn, foot_traffic_df)\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Database error:\", e)\n",
    "    conn.rollback()  \n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01866c3c-a2c3-47b1-82de-1b28b427d72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#23.product_placements table\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "from datetime import timedelta\n",
    "import random\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "number_of_products = 100  \n",
    "number_of_zones = 50 \n",
    "number_of_records = 1000 \n",
    "\n",
    "product_placements_data = []\n",
    "\n",
    "for placement_id in range(1, number_of_records + 1):\n",
    "    product_id = random.randint(1, number_of_products) \n",
    "    zone_id = random.randint(1, number_of_zones) \n",
    "    start_time = fake.date_time_this_year()  \n",
    "    end_time = start_time + timedelta(days=random.randint(1, 30))  \n",
    "    effectiveness_rating = random.randint(1, 5)  \n",
    "\n",
    "    product_placements_data.append({\n",
    "        'placement_id': placement_id,\n",
    "        'product_id': product_id,\n",
    "        'zone_id': zone_id,\n",
    "        'start_time': start_time,\n",
    "        'end_time': end_time,\n",
    "        'effectiveness_rating': effectiveness_rating\n",
    "    })\n",
    "\n",
    "\n",
    "product_placements_df = pd.DataFrame(product_placements_data)\n",
    "\n",
    "print(product_placements_df.head())\n",
    "foot_traffic_df.to_csv('/Users/jintonghe/product_placements.csv', index=False)\n",
    "\n",
    "print(\"CSV file 'product_placements.csv' has been saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aae5ca-0bf2-425d-bb5f-bf358b92ae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "def insert_product_placements_data(conn, df):\n",
    "    cur = conn.cursor()\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO product_placements (placement_id, product_id, zone_id, start_time, end_time, effectiveness_rating)\n",
    "        VALUES %s\n",
    "    \"\"\"\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    execute_values(cur, insert_query, tuples)\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"Final\",\n",
    "        user=\"postgres\",\n",
    "        password=\"123\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "\n",
    "    product_placements_file_path = \"/Users/jintonghe/product_placements.csv\"  \n",
    "    product_placements_df = pd.read_csv(product_placements_file_path)\n",
    "\n",
    "    insert_product_placements_data(conn, product_placements_df)\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Database error:\", e)\n",
    "    conn.rollback()  \n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
